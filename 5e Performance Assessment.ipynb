{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Performance Assessment\n",
    "\n",
    "<img src=\"./img/5_performance_assessment.png\" width=\"500px\"><br><br>\n",
    "\n",
    "If we want to know how good an estimator performs, we can calculate some performance metrics.\n",
    "\n",
    "Here we will dig a little deeper into\n",
    "\n",
    "- Accuracy\n",
    "- Confusion matrices\n",
    "\n",
    "and meet new metrices\n",
    "\n",
    "- Precision\n",
    "- Recall and\n",
    "- F1 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Performance Assessment for kNN based Classification\n",
    "\n",
    "Starting point: We create a classification model using kNN (example from last lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries (basics)\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set k to 7\n",
    "n_neighbors = 7\n",
    "\n",
    "# import some data to play with\n",
    "iris = load_iris()\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# split data (67% training, 33% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an instance of kNN Classifier and fit the data.\n",
    "knn_clf = KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "A Confusion matrix is a figure or a table that is used to describe the performance of a classifier. It is usually extracted from a test dataset for which the ground truth is known. We compare each class with every other class and see how many samples are misclassified. During the construction of this table, we actually come across several key metrics that are very important in the field of machine learning.\n",
    "\n",
    "Let's consider a binary classification case where the output is either 0 or 1:\n",
    "* **True positives:** These are the samples for which we predicted 1 as the output and the ground truth is 1 too.\n",
    "* **True negatives:** These are the samples for which we predicted 0 as the output and the ground truth is 0 too.\n",
    "* **False positives:** These are the samples for which we predicted 1 as the output but the ground truth is 0. This is also known as a Type I error.\n",
    "* **False negatives:** These are the samples for which we predicted 0 as the output but the ground truth is 1. This is also known as a Type II error.\n",
    "\n",
    "Depending on the problem at hand, we may have to optimize our algorithm to reduce the false positive or the false negative rate. For example, in a biometric identification system, it is very important to avoid false positives, because the wrong people might get access to sensitive information. Let's see how to create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define sample labels\n",
    "print(f\"True labels:\\n{y_test}\")\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "print(f\"Predicted labels:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# visualize the confusion matrix\n",
    "ax = plt.axes()\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 30}, cmap=\"Greens\", ax=ax)\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('Accuracy:')\n",
    "print(f' Train: {accuracy_score(y_train, knn_clf.predict(X_train))*100:.2f} %')\n",
    "print(f' Test:  {accuracy_score(y_test, y_pred)*100:.2f} %')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quality measures and cross-validation for a classification model\n",
    "\n",
    "Measures to evaluate the quality of a machine learning technique (precision, recall, accuracy and F1 are the most important ones):<br><br>\n",
    "\n",
    "<img src=\"./img/5_performance_metric.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report (as created by sklearn)\n",
    "print('\\n', classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "<img src=\"./img/5_cross_validation.png\" width=\"700px\"><br><br>\n",
    "\n",
    "`Cross validation` splits the __training data__ into segments (___k-folds___) and trains the model iteratively.\n",
    "\n",
    "Each iteration is then tested against the test set. The errors are leveled out.\n",
    "\n",
    "This allows for higher model quality and generalization capabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating quality measures through cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# this defines the cross-validation strategy (cv parameter)\n",
    "num_folds = 3\n",
    "# 3 means: 3 folds (sets) for cross-validation\n",
    "\n",
    "# Scoring functions of sklearn (original data: X and y!)\n",
    "accuracy_values = model_selection.cross_val_score(knn_clf, X, y, scoring='accuracy', cv=num_folds)\n",
    "print(f\"Accuracy:  {accuracy_values.mean():.2f}% -> {accuracy_values}\")\n",
    "\n",
    "precision_values = model_selection.cross_val_score(knn_clf, X, y, scoring='precision_weighted', cv=num_folds)\n",
    "print(f\"Precision: {precision_values.mean():.2f}% -> {precision_values}\")\n",
    "\n",
    "recall_values = model_selection.cross_val_score(knn_clf, X, y, scoring='recall_weighted', cv=num_folds)\n",
    "print(f\"Recall:    {recall_values.mean():.2f}% -> {recall_values}\")\n",
    "\n",
    "f1_values = model_selection.cross_val_score(knn_clf, X, y, scoring='f1_weighted', cv=num_folds)\n",
    "print(f\"F1:        {f1_values.mean():.2f}  -> {f1_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw decision boundaries\n",
    "DecisionBoundaryDisplay.from_estimator(knn_clf, X, alpha=0.4, response_method=\"predict\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, edgecolor=\"k\")\n",
    "plt.title(\"Decision boundary for kNN Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to our single fold `kNN` classifier, the `cross validation` offers better overall performance:<br><br>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"border: none\">&nbsp;</td>\n",
    "        <td style=\"text-align:center\">single fold kNN</td>\n",
    "        <td style=\"text-align:center\">cross validation kNN</td>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td>Accuracy</td>\n",
    "        <td style=\"text-align:center\">0.76</td>\n",
    "        <td style=\"text-align:center\">0.79</td>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td>Precision</td>\n",
    "        <td style=\"text-align:center\">0.74</td>\n",
    "        <td style=\"text-align:center\">0.81</td>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td>Recall</td>\n",
    "        <td style=\"text-align:center\">0.74</td>\n",
    "        <td style=\"text-align:center\">0.79</td>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td>F1</td>\n",
    "        <td style=\"text-align:center\">0.74</td>\n",
    "        <td style=\"text-align:center\">0.78</td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "<span style=\"font-size:70%\">Cross validation provides higher overall performance measures.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "interpreter": {
   "hash": "cebcd33edd316d35f2057a62d18ade2e0a98bec41e4276bf6b91559eff1be53f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
